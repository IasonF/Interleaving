\documentclass[12pt,a4paper,notitlepage]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{textcomp}
\author{Iason}
\begin{document}

\section*{Summary of changes}

We would first like to thank the reviewers for very useful comments to improve the paper. We have addressed them as explained below.

\subsection*{Referee 1}

\begin{itemize}

\item \textit{The term "irregular" in the paper used to describe the access patterns is not accurate and needs to be better defined. Even though there are access holes in the given example, the access patterns can still be well defined using simple mathematical formula.}

The term irregular has been replaced with more descriptive terms, i.e. application with holes in their access pattern.

\item \textit{In the experimental evaluation, have you also compared the proposed methodology with the state-of-art energy optimization techniques for embedded systems? If so, what is improvement of your approach over theirs?}

Several state-of-the-art techniques are presented as related work. 
Those approaches are not directly applicable for comparison, as it is discussed on Section 3.
The related work is not directly applicable primarily due to differences in the memory architectures and the studied sets of benchmarks. 
The paper hence compares the current approach with previously published work from our groups.
%PGK: Ask Francky if he has a better wording for this. 

\item \textit{Interleaving is only one type of data layout optimization. Have you also tried other more complex optimizations? What is the main reason that you think interleaving is the most suitable/efficient one?}

Array Interleaving is a data layout transformation for combining the storage of multiple arrays, so that blocks of data from different arrays are stored contiguously, with the objective of reducing the number of memory accesses through better spatial locality. \cite{sharma2015array}.
The target applications on the current work benefit most from the proposed methodology, because they are characterized by having access patterns with holes.
Interleaving is a widely used technique that fits the goal of generating more compact sets of data.
An important contribution of the work is the combination of the interleaving optimization with data to memory mapping. 
Having shown the benefits of this, future work can include extending the methodology to be compatible with additional layout optimization techniques.

\textbf{This has been clarified on Section 6.1}

\item \textit{Do you think improving temporal locality of data accesses in cache is also important, if the cache is available? In embedded systems, there should also be a wide range of applications in which the same data need to be accessed multiple times? Thus if temporal locality is exploited, both stalls and number of accesses to main memory can be reduced.}

Improving temporal locality of data accesses in cache is indeed important. 
The proposed architecture uses scratch-pad memories, however, and no cache memory is included in the current study.
Software controlled allocation is a significant feature for the current methodology, as the allocation of data can be fully determined by the designer at design-time.
The basic principles of the methodology are still applicable for hardware controlled caches, but some modifications would be needed to deal with the automatic resolution of hits and misses.
Temporal locality and data reuse are taken into consideration during the interleaving exploration.

\textbf{This has been clarified on Section 4}

\item \textit{Can you add references to the following: 1) simple energy model for evaluating the energy consumption for the motivation example; 2) the commercial memory compiler for SRAM memory models; 3) the XML based language used to describe the architecture.}
\\
\\
\begin{enumerate}
\item A quick estimate of the difference in the energy consumption between the approaches presented in Fig. 1 can be found using a realistic energy model for the memory banks.
The energy model, which has been also presented in \cite{sharma2015array}, is derived from synthesized memory models presented in Sec. 4.
The model is based on realistic estimates of the dynamic and static energy in the memory banks.
The scope is to illustrate the motivation for this work, without extensively describing the detailed memory model characteristics. 
The target architecture and the energy models are described in depth in Sec. 4. 
For the simple model in this chapter, we assume that the static energy is 30\% of the dynamic energy, which is a rational approximation for small memory banks with sizes between 1KB and 16KB.
The static energy increases linearly with the memory size, which is a good approximation as also demonstrated by the detailed models in Sec. 4.
Similarly the approximation for the correlation between the dynamic energy and the memory size is an approximation, which is simple but sufficiently accurate for the motivational example.

\textbf{This has been clarified on Section 2}

\item The commercial memory compiler is part of DesignWare Memory Compilers provided by Synopsys.
The logic libraries support a wide range of foundries and process technologies from 250nm to 28nm. 
The memories are optimized for low power, high performance and high density. A 40nm library was chosen for the current work.  
Of confidentiality reasons we are not allowed to reveal details of the compiler or process and the presented numbers are relative.
%PGK: Check with Francky what he thinks we are allowed to say. I think it is OK to mention Synopsys DesignWare Memory Compiler, but probably not 40LP-TSMC. At least not if the numbers in the tables are actual numbers (not relative). Or are they only relative?

\textbf{This has been clarified on Section 4.1}

\item An XML based language is used to describe the architecture, and a cycle-accurate simulator of the processor is used to simulate the generated code on the architecture. The XML provides a structural way of describing the architecture presented in Fig. 2 including the different components, the parameters of each component, and the relationship between them. The XML description generates a graphical representation of the architecture and is the input for the simulator as presented in \cite{xml}. The chosen simulator is developed for coarse-grained reconfigurable architectures and is suitable in our case, because of the dynamic parameters of our architecture.

\textbf{This has been clarified on Section 4.2}

\end{enumerate}

\item \textit{At the end of page 3, there is such description "The interleaving of the arrays A, B, C and D is shown in Fig.1(c)"? Do you actually mean Fig.1(b)?}
\\
\\
Yes. The error has been fixed.

\item \textit{In Page 9, please rephrase the redundant description, "For efficient utilization of the vector FU, the register file ..."}
\\
\\
The appropriate changes have been made.

\item \textit{In the experimental part, can you comment on why you choose 5 banks? And what will be effect with different number of banks?}
\\
\\
There are two main reasons for exploring architectures up to five memory banks.
Firstly, the energy gains achieved by increasing the number of memory banks in the memory architecture are nearly saturated even for five banks.
In \cite{filippopoulos2013exploration} a group of different applications were studied with regard to their energy consumption on a clustered memory architecture consisting of up to five memory banks.
The results show that depending on the application, the energy gains start to saturate after adding a third or a fourth bank and become insignificant when adding a fifth bank.
Thus, for most applications a memory architecture with five memory banks already provides the necessary reconfiguration options.  
Secondly, the overhead increases exponentially with the number of memory banks, due to the increased complexity of the memory architecture. 
Therefore, memory architectures with six or more banks are typically not efficient options due to the high overhead and the low energy gain.

\textbf{This has been clarified in the first paragraph on Section 5.3.}

\item \textit{Section 6 and Section 7 can be combined as single Section for experimental evaluation.}
\\
\\
The appropriate changes have been made.

\item 
\textit{Typos: \\ 
Page 4: we assume here that he memory \textrightarrow we assume here that the memory\\ 
Page 4: using four banks is presented in Fig.1(b) \textrightarrow using four banks is presented in Fig.1(c) \\ 
Page 4: The data-to-memory mapping for the constructed \textrightarrow The optimized data-to memory mapping for the constructed \\ 
Page 6: that is always accesses \textrightarrow that is always accessed \\ 
Page 7: must developed \textrightarrow must be developed \\ 
Page 8: is higher compared to sleep mode \textrightarrow is higher compared to light sleep mode \\ Page 14: This application is an representative \textrightarrow This application is a representative}
\\
\\
The typos have been fixed.

\end{itemize}

\subsection*{Referee 2}

\begin{itemize}

\item \textit{However, the paper does not clearly distinguish the main contribution and 
the difference from the previous work. Original contribution needs to stand
out clearly.}

The contribution of the proposed work is the development of a combined approach that investigates the interleaving and memory mapping options for a reconfigurable SIMD architecture.  
The current work combines and expands in a non-trivial way, the interleaving exploration presented in \cite{sharma2013data} and the data to memory mapping methodology presented in \cite{filippopoulos2013exploration}. 
The current work is more than a simple application of the two approaches, one after the other.
Such an approach cannot always guarantee a viable solution.
The reason is that for each different interleaving solution, there are a number of constraints on the placement of the data into the memory due to hardware limitations.
If the constraints are not propagated into the data-to-memory mapping step, the final solution suffers from data conflicts.
Different interleaving solutions introduce different constraints. 
Therefore, there is a need to develop an integrated methodology to achieve the improvements of both the approaches.

\textbf{This has been clarified at the end of Section 3.}

\item \textit{It would be interesting to see more workloads analyzed in the framework.}

Unfortunately, it was impossible to analyze more benchmarks for the current revision. 
The chosen applications are representative candidates for the multimedia and the wireless domains.
The results are representative for other applications with the same characteristics.

\item \textit{The paper focuses on SIMD architectures but it does not make any reference memory mapping optimization on GPUs. Also it would be interesting to
see if the framework can capture more irregular access patterns and data mapping schemes (e.g. permutations, indirect addresses, etc.). }

The presented methodology should indeed be applicable in these cases as well. 
Some modifications would be needed, however.
For example, GPUs can exploit computation parallelism, so data should be mapped in different memory banks to be accessed in parallel.
%PGK: Here it would be good if you are able to mention one or two anticipated modifications. 

\item \textit{Some references worth discussing:
Dymaxion: optimizing memory access patterns for heterogeneous systems, SC'11
Data reorganization in memory using 3D-stacked DRAM, ISCA'15
DL: A data layout transformation system for heterogeneous computing, InPar'12}

In \cite{dymaxion} the authors tackle the problem of sub-optimal data structure layouts in GPUs with a large number of parallel cores, especially for programs that are designed with a CPU memory interface in mind. 
An API is presented, that allows programmers to improve CUDA programs by optimizing memory mappings in order to increase the efficiency of memory accesses. 
The main differences of the current work are the platform and the types of code transformations. 
We focus on an SIMD CPU and a dynamic clustered scratchpad memory compared to multicore GPUs and a static memory. 
We differentiate by focusing on interleaving as the preferred code transformation, being suitable for the target applications.
Another work that discusses memory layout for GPUs is presented in \cite{DL}.
The authors focus on off-chip DRAM memory optimization using a number of data layout transformations. 
We differentiate by focusing on the memory closest to the CPU. We also study data interleaving while the main focus in \cite{DL} is the transformations that increase data parallelism, which is more important for their multicore GPU architecture.
In \cite{3D} a number of common data reorganization operations such as shuffle, pack/unpack, swap, transpose, and layout transformations are presented. 
The goal is to study the cost of applying these operations in the memory at run-time. The target memory is 3D-stacked DRAM and additional hardware is employed in order to efficiently perform the reorganization operations with a low overhead. 
Apart from the different type of platform, the current work differentiates in the type of data reorganizations and the mapping of the reorganized data to the scratchpad memory at compilation time. 
%PG: You have added these references to the previous work part of the paper I guess? If not, I think you should.

\textbf{This has been clarified on Section 3.}

\end{itemize}

\subsection*{Referee 3}

\begin{itemize}

\item \textit{In particular, what microarchitecture enhancement is included and how access patterns are extracted (in SW/HW) ?  How address mapping is implemented and its policy?  How interleaving is handled when there are bank conflicts and imperfect coalescing for SIMDs.  In general,  many details are missing.  Fig 3 is not very helpful.}

The application is fully analyzed at design-time, because of the time consuming nature of the task. 
The access patterns are extracted in software and the possible interleaving options are explored. 
The mapping to the specific target architecture is also fully decided at design-time.
The data-to-memory mapping exploration takes into consideration the platform and code limitation and proposes a mapping without data and bank conflicts.
The employment of a scratchpad memory architecture is crucial for this.
In contrast to cache memory systems, in which the mapping of data elements is done at run-time, in scratchpad memory systems the mapping is performed by the programmer or the compiler \cite{ishitobi2007code}. 
Unlike the cache memory, the scratchpad memory does not need tag search operations and it is the responsibility of the programmers or compilers to correctly allocate code and data on the scratchpad memory \cite{steinke2002assigning}.
This is possible for small embedded systems designed to run one or a limited set of specific applications. 
For other types of systems and applications, a cache memory can be the preferred solution as the detection of a cache hit or miss is done automatically and any conflicts can also be resolved by the platform at run-time.
In our case, the application and the memory system are fully analyzed and the allocation of data to a scratchpad memory can be easily done and offers an energy efficient solution.
%PGK: You may need to be a bit more explicit in how you answer the specific questions. E.g., where in your answer do you talk about bank conflicts?. 

\textbf{This has been clarified on Section 5. Changes have been made to better explain the platform and the flow presented in Fig. 3}

\item \textit{Also, the authors may look into the recent work by Akin, et al. "Data Reorganization in Memory Using 3D-stacked DRAM", ISCA 2015.}

In \cite{3D} a number of common data reorganization operations such as shuffle, pack/unpack, swap, transpose, and layout transformations are presented. 
The goal is to study the cost of applying these operations in the memory at run-time. The target memory is 3D-stacked DRAM and additional hardware is employed in order to efficiently perform the reorganization operations with a low overhead. 
Apart from the different type of platform, the current work differentiates in the type of data reorganizations and the mapping of the reorganized data to the scratchpad memory at compilation time.

\textbf{This has been clarified on Section 3.}

\item \textit{A minor point is the chosen benchmarks are not very irregular if appropriate data layouts are chosen.  This is fine, but the authors may consider other possibilities such as graphs and sparse matrices.}

The term irregular has been replaced with more descriptive terms, i.e. application with holes in their access pattern, as also noted by Referee 1. 

\end{itemize}

\bibliographystyle{plain}
\bibliography{reference}
  

\end{document}